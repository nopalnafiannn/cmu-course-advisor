# Document Metadata

**Extraction Date**: 2025-03-21
**Key Concepts**: AI, ###, AI systems, bias, fairness, transparency, this course, risks, CMU, Quiz
**Document Length**: 3101 words

---

# 94885 Responsible AI - Principles, Policies

and Practices
### Meeting Days: Monday & Wednesday

Times: 2:00-3:20 PM
Location: HBH 2003
Semester/Year: Fall 2024
### Units: 6, Section(s): A

Instructor information
### Name Prof Anand Rao

Contact Info anandr2@andrew.cmu.edu
Office location HBH 2105D
Office hours Tuesday, 2:00-3:00 PM
Course Description
As the world rapidly embraces Artificial Intelligence, the potential for both benefit and harm escalates. This course,
"Responsible AI: Principles, Policies, and Practices," navigates the complexities of responsible AI use. Our focus is
on providing a detailed and practical understanding of the key risks and harms traditional and generative AI can
pose, the principles guiding ethical use of AI, and the intricacies of how these harms manifest themselves in the AI
lifecycle. This course places a strong emphasis on bias, fairness, transparency, explainability, safety, security,
privacy, and accountability, demystifying these foundational concepts and highlighting their relevance in the end-toend AI life cycle.

Delve into the regulatory landscape of AI as we dissect policymaking worldwide and scrutinize responsible AI
frameworks adopted by leading organizations. You'll gain valuable insight into the emerging standards,
certifications, and accreditation programs that are guiding the responsible use of AI, Generative AI, and Large
Language Models. Building on this knowledge, the course will help you understand the integral role of governance in
AI and the pivotal role that various stakeholders play in this landscape.

Our unique approach combines theory with practical strategy, enabling you to develop a comprehensive operational
plan for implementing responsible AI within an organization. The course culminates with the creation of a strategy
and handbook tailored to the needs of an organization. Furthermore, we will equip you with the skills to
communicate effectively, making a compelling case for implementing a responsible AI program. Several guest
lectures from practitioners and policy makers, coupled with synthetic case scenarios will give you a window into how
organizations and policy making bodies are advancing the responsible use of AI.

Whether you're a technology enthusiast or policy student, if you possess a basic understanding of data science and
artificial intelligence, this course is a golden opportunity to immerse yourself in the riveting world of responsible AI.

Join us as we explore, analyze, and operationalize Responsible AI from a vantage point that fuses ethical
considerations with technical prowess.

Learning Objectives
### *  Understand and Apply Foundational Principles of Responsible AI: Identify and evaluate key ethical

concepts such as bias, fairness, and transparency, and apply global AI regulatory frameworks to
industry use cases.
### *  Assess Short- and Long-Term AI Risks to Stakeholders: Critically assess the risks and harms AI

poses to different stakeholders (individuals, corporations, society), especially in high-impact sectors like
healthcare and finance.
### *  Apply the NIST AI Risk Management Framework (RMF): Learn to apply the NIST AI RMF to assess

risks in AI systems, focusing on security, fairness, transparency, and governance, and develop practical
strategies for managing these risks across the AI lifecycle.
*  Measure and Mitigate Bias and Fairness in AI Systems: Apply fairness metrics (e.g., demographic
parity, predictive parity) and evaluate strategies for mitigating bias in AI systems, focusing on real-world
applications in healthcare, finance, and criminal justice.
### *  Enhance AI Explainability and Transparency: Apply techniques such as LIME and SHAP to improve

the explainability of AI models, balancing transparency with accuracy for diverse stakeholders in
technical and non-technical roles.
*  Evaluate and Address AI Privacy Risks: Analyze privacy risks in AI systems (e.g., data
reconstruction, membership inference), and apply privacy-enhancing technologies (e.g., differential
privacy, homomorphic encryption) to mitigate these risks.
### *  Ensure AI Safety, Robustness, and Reliability: Measure and manage AI safety risks, including

adversarial attacks and model drift, by implementing adversarial training and stress testing, focusing on
robustness and resilience across deployment environments.
### *  Develop and Apply AI Governance Tools: Apply governance tools, such as AI impact assessments

and algorithmic audits, to ensure the ethical deployment of AI, and compare global approaches to AI
governance (e.g., U.S., EU, Singapore).
### *  Implement Responsible AI Systems in Real-World Contexts: Develop governance frameworks using

real-world case studies, integrating fairness, transparency, safety, and privacy practices to responsibly
manage AI systems.

Learning Resources
The following textbook will serve as a primary reference for the topics discussed.
## 1. Trustworthy AILinks to an external site. by Beena Ammanath, Wiley, March 2022.

Additionally, selected reading materials will be provided for each topic. Two supplementary books that delve into the
course material in greater detail are:
## 1. Responsible AI in the EnterpriseLinks to an external site. by Adnan Masood, Heather Dawe, and Ehsan

Adeli, Packt Publishing, July 2023.
## 2. Machine Learning for High-Risk ApplicationsLinks to an external site. by Patrick Hall, James Curtis, and

Parul Pandey, O’Reilly Media, Inc., April 2023
Assessments
### The final course grade will be calculated using the following categories:

### Assessment Percentage of Final Grade

Class Participation 10%
### Individual Quiz - 1 15%

### Individual Quiz - 2 15%

### Team Project – 1 20%

### Team Project - 2 40%

Total 100%
● Class Participation: Class participation would be based on (a) Coming prepared to the class having read
the pre-reads; (b) Meaningful contributions to the case discussions and insightful questions during the
lectures.
● Quizzes: Two classroom/online quizzes will be administered between Weeks 2 to Week 7 of the course.

Each quiz will be 15% of the total score. Students are NOT allowed to use any AI tools or textbooks for the
quizzes.
● Team Projects: There will be two team projects. One of them will be a team project on bias and fairness
and the other will be a debate and policy formulation There will be no final exam and the presentation will be
conducted during the week of the exams.

Students will be assigned the following final letter grades, based on calculations coming from the course
assessment section.

Grade Percentage Interval
A+ 98.0-100%
A 92.0-97.9%
A- 90.0-91.9%
B+ 88.0-89.9%
B 82.0-87.9%
B- 80.0-81.9%
C+ 78.0-79.9%
C 72.0-77.9%
C- 70.0-71.9%
D 50.0-69.9%
F 00.0-49.9%
Grading Policies
● Late-work policy: To encourage timely submissions and ensure fair and prompt grading for all students,
assignments should be submitted by 11:59 PM on the due date. For those facing unforeseen circumstances,
assignments may be submitted up to 24 hours late for up to 90% of the original grade, with incremental
reductions thereafter. No assignments will be marked after 10 days.
● Make-up work policy: To maintain the integrity of the grading process while offering flexibility, there will be
no make-up assignments or quizzes.
● Re-grade policy: To uphold the integrity of the assessment process, regrading will not be available.

However, students are welcome to discuss the rationale for their grades during office hours to gain a better
understanding of the assessment.
● Attendance and/or participation policy: To emphasize the value of class participation and active
engagement in the learning process, attendance is mandatory and will be tracked via a sign-in sheet.

Students have the flexibility to miss one class without affecting their class participation grade, as outlined in
the Class Participation guidelines.

Course Policies
### *  Academic Integrity & Collaboration: Students are expected to strictly follow Carnegie Mellon University

rules of academic integrity in this course. This means that unless otherwise specified, Individual
assignments are to be the work of the individual student using only permitted material and without any
cooperation of other students or third parties. It also means that usage of work by others is only permitted in
the form of quotations and any such quotation must be distinctively marked to enable identification of the
student’s own work and own ideas. All external sources used must be properly cited, including author
name(s), publication title, year of publication, and a complete reference needed for retrieval. The same work
may not be submitted for credit in multiple courses. Violations will be penalized to the full extent mandated
by the CMU policies. There will be no exceptions.
### *  Use of Generative AI Tools: We encourage students to explore the use of generative artificial intelligence

(AI) tools, such as ChatGPT, for all individual assignments. Any such use must be appropriately
acknowledged and cited, following the guidelines established by the APA Style Guide, including the specific
version of the tool used. Submitted work should include the exact prompt used to generate the content as
well as the AI’s full response in an Appendix. Because AI generated content is not necessarily accurate or
appropriate, it is each student’s responsibility to assess the validity and applicability of any generative AI
output that is submitted. You may not earn full credit if inaccurate, invalid, or inappropriate information is
found in your work. Deviations from these guidelines will be considered violations of CMU’s academic
integrity policy.
### *  Research to Improve the Course:

o For this course, I am conducting educational research. This research will involve analyzing your
coursework. You will not be asked to do anything above and beyond the normal learning activities
and assignments that are part of this course. You are free not to participate in this research, and
your participation will have no influence on your grade for this course or your academic career at
CMU. If you do not wish your course work to be used as research data or if you are under 18 years
of age, please send an email to Chad Hershock (hershock@andrew.cmu.edu), and then your course
data will not be included. You will still be required to complete any activities assigned by the
instructor as part of the learning experience, but your data will not be analyzed for research
purposes.
o If you are asked to do something above and beyond the normal learning activities of the course, you
will be first presented with an informed consent form. Such requests might include participation in
certain types of surveys, focus groups, or other activities and you may choose to participate or not in
the offered research activities.
o Participants will not receive any compensation. The data collected as part of this research will
include student grades. Data analysis of coursework will be conducted after the course is over and
final grades are submitted. In the future, once we have removed all identifiable information from your
data, we may use the data for our future research studies, or we may distribute the data to other
researchers for their research studies. The Eberly Center may provide support on this research
project regarding data analysis and interpretation. The Eberly Center for Teaching Excellence &
Educational Innovation is located on the CMU-Pittsburgh Campus and its mission is to support the
professional development of all CMU instructors regarding teaching and learning. To minimize the
risk of breach of confidentiality, the Eberly Center will never have access to data from this course
containing your personal identifiers. All data will be analyzed in de-identified form and presented in
the aggregate, without any personal identifiers. If you have questions pertaining to your rights as a
research participant, or to report concerns to this study, please contact Chad Hershock
(hershock@andrew.cmu.edu).
● Disabilities: If you have a disability and have an accommodations letter from the Disability Resources
office, I encourage you to discuss your accommodations and needs with me as early in the semester as
possible. I will work with you to ensure that accommodations are provided as appropriate. If you suspect that
you may have a disability and would benefit from accommodations but are not yet registered with the Office
of Disability Resources, I encourage you to contact them at access@andrew.cmu.edu.
● Student wellness: As a student, you may experience a range of challenges that can interfere with learning,
such as strained relationships, increased anxiety, substance use, feeling down, difficulty concentrating
and/or lack of motivation. These mental health concerns or stressful events may diminish your academic
performance and/or reduce your ability to participate in daily activities. CMU services are available, and
treatment does work. You can learn more about confidential mental health services available on campus at
http://www.cmu.edu/counseling . Support is always available (24/7) from Counseling and Psychological
Services: 412-268-2922.
● Diversity: It is my intent that students from all diverse backgrounds and perspectives be well served by this
course, that students’ learning needs be addressed both in and out of class, and that the diversity that
students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present
materials and activities that are respectful of diversity: gender, sexuality, disability, age, socioeconomic
status, ethnicity, race, and culture. Your suggestions are encouraged and appreciated. Please let me know
ways to improve the effectiveness of the course for you personally or for other students or student groups.

Course Schedule
### Date Theme Learning Outcomes Addressed Assignments

Due
M: Oct 21 L1: Understand Responsible AI principles: Introduce bias,
## Introduction fairness, transparency, and their relevance in AI governance.

& Overview
Evaluate AI harms: Assess the impact of AI harms on
stakeholders in sectors like healthcare and finance.

Analyze real-world Cases: Review real-world cases to
explore risks associated with premature AI deployment
Case Study: Responsible AI at tech firms
W: Oct 23 L2: AI Risk Mitigate AI risks: Develop strategies to categorize and (Ungraded
Management address risks in the AI arms race, using practical examples. Quiz)
Apply risk management frameworks: Use the NIST
framework to assess risks and implement governance strategies
across the AI lifecycle
Case Study: Responsible AI at tech firms
M: Oct 28 L3: Mapping Understand bias and fairness in AI systems: Compare statistical
and and social bias definitions using examples from healthcare and
Measuring criminal justice to explore their impact on AI systems.

Bias and
Fairness Evaluate types of bias in the AI lifecycle: Identify and assess
different types of bias (statistical, systemic, cognitive) in AI
development, and analyze their effects on decision-making.

Apply fairness metrics to assess AI bias: Use fairness metrics
like demographic parity and equal opportunity with the Google
PAIR tool to explore trade-offs in AI fairness.

Class Activity: Google PAIR tool
W: Oct 31 L4: Managing Evaluate and apply bias mitigation strategies in AI (Ungraded
Bias and systems: Analyze and apply pre-processing, in-processing, and Quiz)
Fairness post-processing techniques to mitigate bias, assessing their
effectiveness in different AI contexts.

Analyze legal and socio-technical challenges in
fairness: Apply fairness principles to evaluate legal issues like
disparate impact and explore socio-technical challenges in
sectors like criminal justice.
### Assess fairness trade-offs in AI-driven decisionmaking:

Use the Courtroom Algorithm Game to critically evaluate
fairness trade-offs, such as false positives vs. false negatives, in
AI systems used for legal decisions.
### Class Activity: Courtroom Algorithm Game

M: Nov 4 L5: Mapping Map explainability risks and suggest improvements: (Graded) Quiz-1
and Use the NIST AI Risk Management Framework to identify and
Measuring evaluate explainability risks, proposing ways to address
Explainability transparency and interpretability issues in AI systems.
and
Interpretabili Evaluate and compare explainability techniques: Apply
ty LIME and SHAP to assess and compare their effectiveness in
improving explainability, focusing on their clarity for both
technical and non-technical audiences
W: Nov 6 L6: Managing Create strategies for managing explainability: Develop (Ungraded
Explainability stakeholder engagement and compliance strategies using the Quiz)
and NIST AI Risk Management Framework, ensuring transparency
Interpretabili while balancing accuracy and fairness in AI systems.
ty
Propose solutions to balance accuracy and
explainability trade-offs: Analyze case studies like
OptiClaim to evaluate trade-offs, and formulate
recommendations that address the needs of both technical and
non-technical stakeholders.
### Case Study: OptiClaim Solutions

M: Nov 11 L7: Privacy in Map and assess privacy risks in AI systems: Identify key Team Project 1
AI: Mapping, privacy risks, such as data reconstruction and membership
measuring, inference, by mapping them across the AI lifecycle using the
and NIST AI RMF. Apply this mapping to real-world AI systems to
managing pinpoint vulnerabilities.
### Evaluate and apply privacy-enhancing technologies:

Analyze privacy-enhancing techniques like differential privacy
and homomorphic encryption to assess their effectiveness in
mitigating risks. Apply these methods to balance privacy,
accuracy, and compliance in AI systems.

Develop strategies to manage privacy risks and
failures:
Formulate strategies for managing privacy risks using the NIST
AI RMF. Use the Cambridge Analytica case to evaluate failures
and propose improvements in risk management and
transparency.
### Case Study: Cambridge Analytica and Facebook

W: Nov 13 L8: Safety in Classify and map AI safety risks in key domains: (Ungraded
AI: Mapping, Analyze and categorize safety risks, such as physical and legal Quiz)
measuring, harms, using the NIST AI RMF. Evaluate risks in real-world
and contexts, like healthcare and autonomous vehicles, identifying
managing failure points and proposing safety measures.

Measure and monitor AI safety with risk assessment
tools:
Apply safety metrics like adversarial robustness and model drift
detection. Use monitoring techniques to assess real-time risks
in dynamic systems, focusing on financial AI or autonomous
driving.
### Assess strategies to manage AI safety trade-offs:

Develop governance frameworks balancing safety, fairness, and
innovation while engaging stakeholders. Critically evaluate
trade-offs, like privacy vs. safety, using examples from legal AI
and autonomous vehicles.

M: Nov 18 L9: Apply and evaluate robustness techniques in machine (Graded) QuizRobustness learning models: Implement and assess the effectiveness of 2
and techniques like adversarial training and regularization in
Reliability in mitigating distribution shifts and adversarial attacks.

AI: Mapping.

Measuring, Map and measure reliability risks using the NIST AI
and RMF:
managing Use the NIST AI Risk Management Framework to map and
evaluate reliability risks, focusing on model performance,
stability, and reproducibility across different scenarios.

Design and implement strategies to manage
robustness and reliability risks: Apply the NIST AI RMF
to develop risk management strategies that improve model
reliability, ensuring robust and stable performance in realworld applications.

W: Nov 20 L10: AI Apply NIST AI RMF in real-world governance contexts: (Ungraded
Governance Use the NIST AI RMF to assess governance challenges and Quiz)
propose risk management strategies, applying its core functions
(Govern, Map, Measure, Manage) to mitigate risks in industryspecific AI systems.
(cid:0) Analyze global AI governance trends:
Compare and evaluate AI governance frameworks from the
U.S., EU, and Singapore, using case studies to assess the
effectiveness of these models in managing AI risks and ensuring
compliance with current laws.
### Assess ethical and social risks in AI systems:

Apply AI assurance methods, such as impact assessments and
algorithmic audits, to identify and mitigate risks related to bias,
transparency, and environmental harm in AI systems across
various sectors.
### M: Nov 25 Debate Debate Team Project 2

### - Debate

### W: Nov 27 Thanksgiving No Class

holiday
### M: Dec 2 Guest Lecture TBD

- 1
### W: Dec 4 Guest Lecture TBD Team Project 2

### - 2 – Final Report

due
9